{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "colab": {
   "name": "Homework.ipynb",
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "TQ9fQTjZhiTf"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy.spatial.distance import euclidean\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "# For results repeatability\n",
    "np.random.seed(0)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_biG4sLLhiTp"
   },
   "source": [
    "# Dataset preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EL7GvsezhiTs"
   },
   "source": [
    "## Dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUVIv7glhiTt"
   },
   "source": [
    "A function to upload and preprocess data in the \"adults\" format."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "injPNctshiTu"
   },
   "source": [
    "def get_clean_dataset1(data_file):\n",
    "    dataset = pd.read_csv(data_file, header=None)\n",
    "    dataset.columns = [\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"salary\"]\n",
    "    dataset = dataset[(dataset!=\" ?\").all(axis=1)].reset_index(drop=True)\n",
    "    df_strings = dataset.select_dtypes(['object'])\n",
    "    dataset[df_strings.columns] = df_strings.apply(lambda x: x.str.strip())\n",
    "    clean_dataset = pd.DataFrame(dataset[\"age\"])\n",
    "    for col in dataset.columns[1:-1]:\n",
    "        if(dataset[col].dtype =='O'):\n",
    "            clean_dataset = clean_dataset.join(pd.get_dummies(dataset[col], prefix=col))\n",
    "        else:\n",
    "            clean_dataset = clean_dataset.join(dataset[col])\n",
    "    labels = (dataset[\"salary\"]==\">50K\")*1\n",
    "    return clean_dataset, labels"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXKmLRhRhiTx"
   },
   "source": [
    "### Training / Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "90rsMSoGhiTy"
   },
   "source": [
    "dataset_adult, labels_adult = get_clean_dataset1(\"data/adult.data\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5TG3DkvhiT0"
   },
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NeZO71P7hiT2"
   },
   "source": [
    "test_dataset_adult, test_labels_adult = get_clean_dataset1(\"data/adult.test\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZgsWYitGhiT5"
   },
   "source": [
    "## Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rVCg0XtghiT7"
   },
   "source": [
    "def get_clean_dataset2(data_file):\n",
    "    dataset = pd.read_csv(data_file, header=None)\n",
    "    dataset.columns = [\"white_king_column\",\"white_king_row\",\"white_rook_column\",\"white_rook_row\",\"black_king_column\",\"black_king_row\", \"outcome\"]\n",
    "    df_strings = dataset.select_dtypes(['object'])\n",
    "    dataset[df_strings.columns] = df_strings.apply(lambda x: x.str.strip())\n",
    "    clean_dataset = pd.DataFrame()\n",
    "    for col in dataset.columns[0:-1]:\n",
    "        if(dataset[col].dtype =='O'):\n",
    "            clean_dataset = clean_dataset.join(pd.get_dummies(dataset[col], prefix=col))\n",
    "        else:\n",
    "            clean_dataset = clean_dataset.join(dataset[col])\n",
    "\n",
    "    labels = (dataset[\"outcome\"]!=\"draw\")*1\n",
    "    return clean_dataset, labels"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6sRVV7ehiT7"
   },
   "source": [
    "### Training / Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RP_VMe4khiT8"
   },
   "source": [
    "dataset_chess, labels_chess = get_clean_dataset1(\"data/krkopt.data\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGWdZarShiT_"
   },
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QKkr73QFhiT_"
   },
   "source": [
    "test_dataset_chess, test_labels_chess = get_clean_dataset1(\"data/krkopt.test\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tmeCexehiUA"
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OqWPXTInhiUA"
   },
   "source": [
    "def plotMeanAndStd(stats, x, color='b', ax = None, legend=None):\n",
    "    \"\"\"\n",
    "    Input : array of tuples (mean std) and their x coordinates\n",
    "    \"\"\"\n",
    "    mean = np.array([s[0] for s in stats])\n",
    "    standard_dev = np.array([s[1] for s in stats])\n",
    "    if ax == None :\n",
    "        plt.plot(x, mean, c=color,label=legend)\n",
    "        plt.fill_between(x, mean-standard_dev, mean+standard_dev, alpha=0.2, color=color)\n",
    "    else:\n",
    "        ax.plot(x, mean, c=color,label=legend)\n",
    "        ax.fill_between(x, mean-standard_dev, mean+standard_dev, alpha=0.2, color=color)  "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tOLE_2SPhiUB"
   },
   "source": [
    "def error(predicted_labels, real_labels, loss=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    Input: numpy array containing respectively the labels an algorithm predicted, and the real labels corresponding\n",
    "    to the data. Type of loss we want to use.\n",
    "    \n",
    "    Output: float, the computed loss.\n",
    "    \"\"\"\n",
    "    if loss == \"euclidean\": return euclidean(predicted_labels, real_labels)\n",
    "    elif loss == \"manhattan\": return sum(abs(predicted_labels - real_labels))\n",
    "    \n",
    "    "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Givn177fhiUC"
   },
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_GZtGu3vhiUC"
   },
   "source": [
    "def cross_validation(algo, dataset_, labels_, loss_=\"manhattan\", folds = 5, algo_kwargs={}):\n",
    "    \"\"\"\n",
    "    Input : Predictor function that works by supplying training set and labels and test set and return predicted labels\n",
    "            dataset  and corresponding labels\n",
    "            folds\n",
    "            algo_kwargs : a dict with additional params for the algo : ex. {'n_neighbors':5}\n",
    "    Output : Precision mean and variance\n",
    "    \"\"\"\n",
    "    dataset_size = dataset_.shape[0]\n",
    "    group_ids = np.tile(np.arange(folds),int(dataset_size/folds)+1)[:dataset_size]\n",
    "    np.random.shuffle(group_ids)\n",
    "    training_precisions = []\n",
    "    validation_precisions = []\n",
    "    for N in range(folds):\n",
    "        training_set = dataset_[group_ids != N]\n",
    "        training_labels = labels_[group_ids != N]\n",
    "        test_set = dataset_[group_ids == N]\n",
    "        test_labels = labels_[group_ids == N]\n",
    "        # Training error\n",
    "        training_predicted_labels = algo(training_set, training_labels, training_set, **algo_kwargs)\n",
    "        training_precisions += [(len(training_labels) - error(training_predicted_labels, training_labels, loss = loss_))/len(training_labels)]\n",
    "    \n",
    "        \n",
    "        # Validation error\n",
    "        validation_predicted_labels = algo(training_set, training_labels, test_set, **algo_kwargs)\n",
    "        validation_precisions += [(len(test_labels) - error(validation_predicted_labels, test_labels, loss = loss_))/len(test_labels)]\n",
    "    \n",
    "    \n",
    "    return (np.mean(training_precisions), np.std(training_precisions), np.mean(validation_precisions), np.std(validation_precisions))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCANGo53hiUE"
   },
   "source": [
    "# Knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFbCGSeXhiUF"
   },
   "source": [
    "We use scikit-learn's knn function to design a knn classifier."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bHhrp7RchiUF"
   },
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RUIengFqhiUG"
   },
   "source": [
    "def knn(training_features, training_labels, to_predict_features,\n",
    "        n_neighbors=5, weights = \"uniform\", algorithm=\"auto\", p=2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input: Training data, features for which we want to predict the labels, number of neighbors k for knn algo,\n",
    "    features weights system (uniform or distance), algorithm usewd to find closer k neighbors, p is the value\n",
    "    used in the computation of the minkowski distance that is used here, p=1 gives a manhattan distance, p=2 a\n",
    "    euclidian distance.\n",
    "    \n",
    "    Output: Numpy array containing the labels predicted by KNN for the given 'to_predict_features'\n",
    "    \"\"\"\n",
    "    neigh = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm=algorithm, p=p)\n",
    "    neigh.fit(training_features, training_labels)\n",
    "    \n",
    "    return neigh.predict(to_predict_features)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xn8B6ekvhiUH"
   },
   "source": [
    "Let us study the influence of the hyperparameter k (number of neighbors) on KNN algorithm's performance."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aAmoxWKZhiUH"
   },
   "source": [
    "def n_neighbors_influence_multiple_datasize(Ks, dataset_, labels_, N_start, N_end, N_step, loss_=\"manhattan\",\n",
    "                                            folds = 5, show_time=False, visualize=True):\n",
    "    \n",
    "    mean_training_per_k = dict()\n",
    "    std_training_per_k = dict()\n",
    "    mean_validation_per_k = dict()\n",
    "    std_validation_per_k = dict()\n",
    "    \n",
    "    if show_time: time_per_k = dict()\n",
    "    \n",
    "    for k in Ks:\n",
    "        print(k)\n",
    "        if show_time: (mean_trainings, std_trainings, mean_validations, std_validations, times) = data_size_influence(knn, dataset_, labels_, N_start, N_end, N_step, loss_=\"manhattan\", folds = folds, algo_kwargs={\"n_neighbors\":k}, show_time=show_time, visualize=False)\n",
    "        else: (mean_trainings, std_trainings, mean_validations, std_validations) = data_size_influence(knn, dataset_, labels_, N_start, N_end, N_step, loss_=\"manhattan\", folds = folds, algo_kwargs={\"n_neighbors\":k}, show_time=show_time, visualize=False)\n",
    "            \n",
    "        mean_training_per_k[k] = mean_trainings\n",
    "        std_training_per_k[k] = std_trainings\n",
    "        mean_validation_per_k[k]  = mean_validations\n",
    "        std_validation_per_k[k]  = std_validations\n",
    "\n",
    "        if show_time: time_per_k[k]  = times\n",
    "    \n",
    "    if visualize:\n",
    "        \n",
    "        Ns = list(range(N_start, N_end, N_step))\n",
    "        \n",
    "        fig = plt.figure(figsize=(10,7))\n",
    "        fig.suptitle(\"Influence of K (in k nearest neighbor) and training/validation dataset size\")\n",
    "        \n",
    "        ax1 = fig.add_subplot(231)\n",
    "        ax1.title.set_text(\"Mean training precision\")\n",
    "        for k in Ks:\n",
    "            ax1.plot(Ns, mean_training_per_k[k], label=f\"k={k}\")\n",
    "        plt.legend()\n",
    "\n",
    "        ax2 = fig.add_subplot(232)\n",
    "        ax2.title.set_text(\"Training precision's standard deviation\")\n",
    "        for k in Ks:\n",
    "            ax2.plot(Ns, std_training_per_k[k], label=f\"k={k}\")\n",
    "        plt.legend()\n",
    "\n",
    "        ax3 = fig.add_subplot(233)\n",
    "        ax3.title.set_text(\"Mean validation precision\")\n",
    "        for k in Ks:\n",
    "            ax3.plot(Ns, mean_validation_per_k[k], label=f\"k={k}\")\n",
    "        plt.legend()\n",
    "\n",
    "        ax4 = fig.add_subplot(234)\n",
    "        ax4.title.set_text(\"Validation precision's standard deviation\")\n",
    "        for k in Ks:\n",
    "            ax4.plot(Ns, std_validation_per_k[k], label=f\"k={k}\")\n",
    "        plt.legend()\n",
    "\n",
    "        if show_time:\n",
    "            ax5 = fig.add_subplot(235)\n",
    "            ax5.title.set_text(\"Computation time\")\n",
    "            for k in Ks:\n",
    "                ax5.plot(Ns, time_per_k[k], label=f\"k={k}\")\n",
    "            plt.legend()\n",
    "        \n",
    "        \n",
    "        plt.subplots_adjust(left=0.1,\n",
    "                        bottom=0.1, \n",
    "                        right=3, \n",
    "                        top=3, \n",
    "                        wspace=1, \n",
    "                        hspace=1)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    if show_time: return (mean_training_per_k, std_training_per_k, mean_validation_per_k, std_validation_per_k, time_per_k)\n",
    "    else: return (mean_training_per_k, std_training_per_k, mean_validation_per_k, std_validation_per_k)\n",
    "    "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Dt4zxc5thiUJ"
   },
   "source": [
    "n_neighbors_influence_multiple_datasize(list(range(1, 6)), dataset_adult, labels_adult, 50, 10000, 500, loss_=\"manhattan\",\n",
    "                          folds = 5, show_time=False, visualize=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "53lnubXDhiUK"
   },
   "source": [
    "def n_neighbors_influence_fixed_datasize(Ks, dataset_, labels_, N, loss_=\"manhattan\",\n",
    "                                         folds = 5, show_time=False, visualize=True):\n",
    "    nrows = dataset_.shape[0]\n",
    "    mean_trainings = []\n",
    "    std_trainings = []\n",
    "    mean_validations = []\n",
    "    std_validations = []\n",
    "    \n",
    "    if show_time: times = []\n",
    "    \n",
    "    for k in Ks:\n",
    "        indices = list(np.random.choice(nrows, N))\n",
    "        d = dataset_.iloc[indices]\n",
    "        l = labels_.iloc[indices]\n",
    "        \n",
    "        if show_time: t = time.time()\n",
    "        mean_training, std_training, mean_validation, std_validation = cross_validation(knn, d, l, folds = folds, algo_kwargs={\"n_neighbors\": k})\n",
    "        if show_time: times.append(time.time() - t)\n",
    "        \n",
    "        mean_trainings.append(mean_training)\n",
    "        std_trainings.append(std_training)\n",
    "        mean_validations.append(mean_validation)\n",
    "        std_validations.append(std_validation)\n",
    "    \n",
    "    if visualize:\n",
    "        fig = plt.figure(figsize=(10,7))\n",
    "        fig.suptitle(\"Influence of training/validation dataset size\")\n",
    "        ax1 = fig.add_subplot(231)\n",
    "        ax1.title.set_text(\"Mean training precision\")\n",
    "        ax1.plot(Ks, mean_trainings)\n",
    "\n",
    "        ax2 = fig.add_subplot(232)\n",
    "        ax2.title.set_text(\"Training precision's standard deviation\")\n",
    "        ax2.plot(Ks, std_trainings)\n",
    "\n",
    "        ax3 = fig.add_subplot(233)\n",
    "        ax3.title.set_text(\"Mean validation precision\")\n",
    "        ax3.plot(Ks, mean_validations)\n",
    "\n",
    "        ax4 = fig.add_subplot(234)\n",
    "        ax4.title.set_text(\"Validation precision's standard deviation\")\n",
    "        ax4.plot(Ks, std_validations)\n",
    "\n",
    "        if show_time:\n",
    "            ax5 = fig.add_subplot(235)\n",
    "            ax5.title.set_text(\"Computation time\")\n",
    "            ax5.plot(Ks, times)\n",
    "        \n",
    "        plt.subplots_adjust(left=0.1,\n",
    "                        bottom=0.1, \n",
    "                        right=3, \n",
    "                        top=3, \n",
    "                        wspace=1, \n",
    "                        hspace=1)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    if show_time: return (mean_trainings, std_trainings, mean_validations, std_validations, times)\n",
    "    else: \n",
    "        return (mean_trainings, std_trainings, mean_validations, std_validations)\n",
    "    "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5q8G-pJchiUL"
   },
   "source": [
    " n_neighbors_influence_fixed_datasize(list(range(1, 100)), dataset_adult, labels_adult, 2000, loss_=\"manhattan\",\n",
    "                                         folds = 5, show_time=False, visualize=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RflEuMffhiUM"
   },
   "source": [
    "### Knn results for dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mmQqwBWhiUM"
   },
   "source": [
    "##### Selecting best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Q_ZLN_qPhiUN"
   },
   "source": [
    "# TO DO : plot the performance depending on K for the entire dataset, choose simplest best K"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yItfwVREhiUN"
   },
   "source": [
    "##### Results on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mvvhRXUfhiUO"
   },
   "source": [
    "# TO DO : print precision of test dataset, add confusion matrix"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvxZzs7EhiUO"
   },
   "source": [
    "### Knn results for dataset 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TB9oc6y0hiUP"
   },
   "source": [
    "##### Selecting best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HBchGgoshiUP"
   },
   "source": [
    "# TO DO : plot the performance depending on K for the entire dataset, choose simplest best K"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_vQSdO2hiUQ"
   },
   "source": [
    "##### Results on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XjfDL3_NhiUQ"
   },
   "source": [
    "# TO DO : print precision of test dataset, add confusion matrix"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGgE3GtJhiUQ"
   },
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1czo2QT4hiUR"
   },
   "source": [
    "We use scikit-learn's decision tree function to design a decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "uO9tUgiNhiUR"
   },
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8HEiu5H3hiUR"
   },
   "source": [
    "def decision_tree(training_features, training_labels, to_predict_features,\n",
    "                  criterion='gini', splitter='best'):\n",
    "    \"\"\"\n",
    "    :param training_features: training features (x)\n",
    "    :param training_labels: training labels (y)\n",
    "    :param to_predict_features: features that we want to predict\n",
    "    :param criterion: {\"best\", \"random\"} Default is \"gini\" for the Gini impurity and \"entropy\" for the information gain\n",
    "    :param splitter: {\"best\", \"random\"} Default is \"best\" to choose the best split and \"random\" to choose the best random split.\n",
    "    :return:Numpy array containing the labels predicted by Decision Tree for the given 'to_predict_features'\n",
    "    \"\"\"\n",
    "    classifier = DecisionTreeClassifier(criterion=criterion, splitter=splitter)\n",
    "    classifier.fit(training_features, training_labels)\n",
    "    \n",
    "    return classifier.predict(to_predict_features)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LsA0O9nIhiUR"
   },
   "source": [
    "# TO DO : see influence of cost function on precision (same graph as for KNN : dataset size on x axis, one trace for each cost function)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PgZFWL9zhiUS"
   },
   "source": [
    "# TO DO : see influence of max depth on precision (same graph as for KNN : fixed data set size, max depth on x axis, precision on y)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "104uJclihiUS"
   },
   "source": [
    "### Decision tree results for dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UElk887whiUS"
   },
   "source": [
    "##### Selecting best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eBxF9uTRhiUT"
   },
   "source": [
    "#TO DO plot precision depending on max depth, one line for each cost function, selecting simplest best model"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ANuC-VchiUT"
   },
   "source": [
    "##### Results on dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j8Y6ADh_hiUT"
   },
   "source": [
    "# Print precision and confusion matrix on test dataset"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnGbkZlrhiUU"
   },
   "source": [
    "### Decision tree results for dataset 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcFCI5xkhiUU"
   },
   "source": [
    "##### Selecting best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CMWoniQkhiUU"
   },
   "source": [
    "#TO DO plot precision depending on max depth, one line for each cost function, selecting simplest best model"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hpd4LWoghiUU"
   },
   "source": [
    "#### Results on dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4WBxebSAhiUV"
   },
   "source": [
    "# Print precision and confusion matrix on test dataset"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvvzULNjhiUV"
   },
   "source": [
    "# Influence of dataset's size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzYZsoQlhiUV"
   },
   "source": [
    "Now we study the influence of the size of the training / validation dataset on the training / validation errors."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZHaJgF0ohiUV"
   },
   "source": [
    "def data_size_influence(algo, dataset_, labels_, N_start, N_end, N_step, loss_=\"manhattan\", folds = 5, algo_kwargs={}, show_time=False, visualize=True):\n",
    "    \n",
    "    nrows = dataset_.shape[0]\n",
    "    Ns = []\n",
    "    mean_trainings = []\n",
    "    std_trainings = []\n",
    "    mean_validations = []\n",
    "    std_validations = []\n",
    "    \n",
    "    if show_time: times = []\n",
    "    \n",
    "    for N in range(N_start, N_end, N_step):\n",
    "        Ns.append(N)\n",
    "        indices = list(np.random.choice(nrows, N))\n",
    "        d = dataset_.iloc[indices]\n",
    "        l = labels_.iloc[indices]\n",
    "        \n",
    "        if show_time: t = time.time()\n",
    "        mean_training, std_training, mean_validation, std_validation = cross_validation(knn, d, l, folds = folds, algo_kwargs=algo_kwargs)\n",
    "        if show_time: times.append(time.time() - t)\n",
    "        \n",
    "        mean_trainings.append(mean_training)\n",
    "        std_trainings.append(std_training)\n",
    "        mean_validations.append(mean_validation)\n",
    "        std_validations.append(std_validation)\n",
    "    \n",
    "    if visualize:\n",
    "        fig = plt.figure(figsize=(10,7))\n",
    "        fig.suptitle(\"Influence of training/validation dataset size\")\n",
    "        ax1 = fig.gca()\n",
    "        plotMeanAndStd([i for i in zip(mean_trainings, std_trainings)],Ns, ax= ax1, legend = \"Training\", color='red')\n",
    "        plotMeanAndStd([i for i in zip(mean_validations, std_validations)],Ns, ax= ax1, legend = \"Validation\",color='blue')\n",
    "        ax1.legend(loc=\"lower right\")\n",
    "        ax1.set_ylabel(\"Precision\")\n",
    "        ax1.set_xlabel(\"Dataset sample size\")\n",
    "        ax1.grid()\n",
    "\n",
    "        if show_time:\n",
    "            ax5 = ax1.twinx()\n",
    "            ax5.set_ylabel(\"Computation time (s)\")\n",
    "            ax5.plot(Ns, times, label =\"Computation time\", c=\"orange\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    if show_time: return (mean_trainings, std_trainings, mean_validations, std_validations, times)\n",
    "    else: return (mean_trainings, std_trainings, mean_validations, std_validations)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wY1YjPephiUW"
   },
   "source": [
    "data_size_influence(knn, dataset_adult, labels_adult, 50, 10000, 1000, loss_=\"manhattan\", folds = 5, algo_kwargs={\"n_neighbors\":3}, show_time=True, visualize=True)\n",
    "pass"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KF22sDhFhiUX"
   },
   "source": [
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WuRHWlRBhiUY"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5yHI7yS5hiUY"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
