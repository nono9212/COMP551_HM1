{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "colab": {
   "name": "Homework.ipynb",
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "TQ9fQTjZhiTf"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy.spatial.distance import euclidean\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "# For results repeatability\n",
    "np.random.seed(0)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_biG4sLLhiTp"
   },
   "source": [
    "# Dataset preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EL7GvsezhiTs"
   },
   "source": [
    "## Dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUVIv7glhiTt"
   },
   "source": [
    "A function to upload and preprocess data in the \"adults\" format."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "injPNctshiTu"
   },
   "source": [
    "def get_clean_dataset1(data_file):\n",
    "    dataset = pd.read_csv(data_file, header=None)\n",
    "    dataset.columns = [\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"salary\"]\n",
    "    dataset = dataset[(dataset!=\" ?\").all(axis=1)].reset_index(drop=True)\n",
    "    df_strings = dataset.select_dtypes(['object'])\n",
    "    dataset[df_strings.columns] = df_strings.apply(lambda x: x.str.strip())\n",
    "    clean_dataset = pd.DataFrame(dataset[\"age\"])\n",
    "    for col in dataset.columns[1:-1]:\n",
    "        if(dataset[col].dtype =='O'):\n",
    "            clean_dataset = clean_dataset.join(pd.get_dummies(dataset[col], prefix=col))\n",
    "        else:\n",
    "            clean_dataset = clean_dataset.join(dataset[col])\n",
    "    labels = (dataset[\"salary\"]==\">50K\")*1\n",
    "    return clean_dataset, labels"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXKmLRhRhiTx"
   },
   "source": [
    "### Training / Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "90rsMSoGhiTy"
   },
   "source": [
    "dataset_adult, labels_adult = get_clean_dataset1(\"data/adult.data\")"
   ],
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, labels = get_clean_dataset1(\"data/adult.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5TG3DkvhiT0"
   },
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NeZO71P7hiT2"
   },
   "source": [
    "test_dataset_adult, test_labels_adult = get_clean_dataset1(\"data/adult.test\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZgsWYitGhiT5"
   },
   "source": [
    "## Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rVCg0XtghiT7"
   },
   "source": [
    "def get_clean_dataset2(data_file):\n",
    "    dataset = pd.read_csv(data_file, header=None)\n",
    "    dataset.columns = [\"white_king_column\",\"white_king_row\",\"white_rook_column\",\"white_rook_row\",\"black_king_column\",\"black_king_row\", \"outcome\"]\n",
    "    df_strings = dataset.select_dtypes(['object'])\n",
    "    dataset[df_strings.columns] = df_strings.apply(lambda x: x.str.strip())\n",
    "    clean_dataset = pd.DataFrame()\n",
    "    for col in dataset.columns[0:-1]:\n",
    "        if(dataset[col].dtype =='O'):\n",
    "            clean_dataset = clean_dataset.join(pd.get_dummies(dataset[col], prefix=col))\n",
    "        else:\n",
    "            clean_dataset = clean_dataset.join(dataset[col])\n",
    "\n",
    "    labels = (dataset[\"outcome\"]!=\"draw\")*1\n",
    "    return clean_dataset, labels"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6sRVV7ehiT7"
   },
   "source": [
    "### Training / Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RP_VMe4khiT8"
   },
   "source": [
    "dataset_chess, labels_chess = get_clean_dataset1(\"data/krkopt.data\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGWdZarShiT_"
   },
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QKkr73QFhiT_"
   },
   "source": [
    "test_dataset_chess, test_labels_chess = get_clean_dataset1(\"data/krkopt.test\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tmeCexehiUA"
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting function"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OqWPXTInhiUA"
   },
   "source": [
    "def plotMeanAndStd(stats, x, color='b', ax = None, legend=None):\n",
    "    \"\"\"\n",
    "    Input : array of tuples (mean std) and their x coordinates\n",
    "    \"\"\"\n",
    "    mean = np.array([s[0] for s in stats])\n",
    "    standard_dev = np.array([s[1] for s in stats])\n",
    "    if ax == None :\n",
    "        plt.plot(x, mean, c=color,label=legend)\n",
    "        plt.fill_between(x, mean-standard_dev, mean+standard_dev, alpha=0.2, color=color)\n",
    "    else:\n",
    "        ax.plot(x, mean, c=color,label=legend)\n",
    "        ax.fill_between(x, mean-standard_dev, mean+standard_dev, alpha=0.2, color=color)  "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error measure"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tOLE_2SPhiUB"
   },
   "source": [
    "def error(predicted_labels, real_labels, loss=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    Input: numpy array containing respectively the labels an algorithm predicted, and the real labels corresponding\n",
    "    to the data. Type of loss we want to use.\n",
    "    \n",
    "    Output: float, the computed loss.\n",
    "    \"\"\"\n",
    "    if loss == \"euclidean\": return euclidean(predicted_labels, real_labels)\n",
    "    elif loss == \"manhattan\": return sum(abs(predicted_labels - real_labels))\n",
    "    \n",
    "    "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Givn177fhiUC"
   },
   "source": [
    "### Features normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add the possibility to perform data normalization with scikit-learn's scaler to avoid having overweighted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(dataset):\n",
    "    columns = dataset.columns\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(dataset)\n",
    "    dataset[columns] = scaler.transform(dataset[columns])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_features(dataset, weights):\n",
    "    \"\"\"\n",
    "    Input: a dataset (pandas dataframe), and a dictionary giving each dataset's feature a weight\n",
    "    according to their importance\n",
    "    \n",
    "    Output: None, but dataset's features have been multiplied by their weight to take into account the\n",
    "    differences in their importance\n",
    "    \"\"\"\n",
    "    for feature in weights:\n",
    "        dataset[feature] *= weights[feature]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_GZtGu3vhiUC"
   },
   "source": [
    "def cross_validation(algo, dataset_, labels_, loss_=\"manhattan\", folds = 5, algo_kwargs={}):\n",
    "    \"\"\"\n",
    "    Input : Predictor function that works by supplying training set and labels and test set and return predicted labels\n",
    "            dataset  and corresponding labels\n",
    "            folds\n",
    "            algo_kwargs : a dict with additional params for the algo : ex. {'n_neighbors':5}\n",
    "    Output : Precision mean and variance\n",
    "    \"\"\"\n",
    "    dataset_size = dataset_.shape[0]\n",
    "    group_ids = np.tile(np.arange(folds),int(dataset_size/folds)+1)[:dataset_size]\n",
    "    np.random.shuffle(group_ids)\n",
    "    training_precisions = []\n",
    "    validation_precisions = []\n",
    "    for N in range(folds):\n",
    "        training_set = dataset_[group_ids != N]\n",
    "        training_labels = labels_[group_ids != N]\n",
    "        test_set = dataset_[group_ids == N]\n",
    "        test_labels = labels_[group_ids == N]\n",
    "        # Training error\n",
    "        training_predicted_labels = algo(training_set, training_labels, training_set, **algo_kwargs)\n",
    "        training_precisions += [(len(training_labels) - error(training_predicted_labels, training_labels, loss = loss_))/len(training_labels)]\n",
    "    \n",
    "        \n",
    "        # Validation error\n",
    "        validation_predicted_labels = algo(training_set, training_labels, test_set, **algo_kwargs)\n",
    "        validation_precisions += [(len(test_labels) - error(validation_predicted_labels, test_labels, loss = loss_))/len(test_labels)]\n",
    "    \n",
    "    \n",
    "    return (np.mean(training_precisions), np.std(training_precisions), np.mean(validation_precisions), np.std(validation_precisions))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_size_influence(algo, dataset_, labels_, N_start, N_end, N_step, loss_=\"manhattan\", folds = 5, algo_kwargs={}, show_time=False, visualize=True):\n",
    "    \n",
    "    nrows = dataset_.shape[0]\n",
    "    Ns = []\n",
    "    mean_trainings = []\n",
    "    std_trainings = []\n",
    "    mean_validations = []\n",
    "    std_validations = []\n",
    "    \n",
    "    if show_time: times = []\n",
    "    \n",
    "    for N in range(N_start, N_end, N_step):\n",
    "        Ns.append(N)\n",
    "        indices = list(np.random.choice(nrows, N))\n",
    "        d = dataset.iloc[indices]\n",
    "        l = labels.iloc[indices]\n",
    "        \n",
    "        if show_time: t = time.time()\n",
    "        mean_training, std_training, mean_validation, std_validation = cross_validation(knn, d, l, folds = folds, algo_kwargs=algo_kwargs)\n",
    "        if show_time: times.append(time.time() - t)\n",
    "        \n",
    "        mean_trainings.append(mean_training)\n",
    "        std_trainings.append(std_training)\n",
    "        mean_validations.append(mean_validation)\n",
    "        std_validations.append(std_validation)\n",
    "    \n",
    "    if visualize:\n",
    "        fig = plt.figure(figsize=(10,7))\n",
    "        fig.suptitle(\"Influence of training/validation dataset size\")\n",
    "        ax1 = fig.gca()\n",
    "        plotMeanAndStd([i for i in zip(mean_trainings, std_trainings)],Ns, ax= ax1, legend = \"Training\", color='red')\n",
    "        plotMeanAndStd([i for i in zip(mean_validations, std_validations)],Ns, ax= ax1, legend = \"Validation\",color='blue')\n",
    "        ax1.legend(loc=\"lower right\")\n",
    "        ax1.set_ylabel(\"Precision\")\n",
    "        ax1.set_xlabel(\"Dataset sample size\")\n",
    "        ax1.grid()\n",
    "\n",
    "        if show_time:\n",
    "            ax5 = ax1.twinx()\n",
    "            ax5.set_ylabel(\"Computation time (s)\")\n",
    "            ax5.plot(Ns, times, label =\"Computation time\", c=\"orange\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    if show_time: return (mean_trainings, std_trainings, mean_validations, std_validations, times)\n",
    "    else: return (mean_trainings, std_trainings, mean_validations, std_validations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCANGo53hiUE"
   },
   "source": [
    "# Knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFbCGSeXhiUF"
   },
   "source": [
    "### Knn algorithm implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use scikit-learn's knn function to design a knn classifier."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bHhrp7RchiUF"
   },
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RUIengFqhiUG"
   },
   "source": [
    "def knn(training_features, training_labels, to_predict_features,\n",
    "        n_neighbors=5, weights = \"uniform\", algorithm=\"auto\", p=2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input: Training data, features for which we want to predict the labels, number of neighbors k for knn algo,\n",
    "    features weights system (uniform or distance), algorithm usewd to find closer k neighbors, p is the value\n",
    "    used in the computation of the minkowski distance that is used here, p=1 gives a manhattan distance, p=2 a\n",
    "    euclidian distance.\n",
    "    \n",
    "    Output: Numpy array containing the labels predicted by KNN for the given 'to_predict_features'\n",
    "    \"\"\"\n",
    "    neigh = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm=algorithm, p=p)\n",
    "    neigh.fit(training_features, training_labels)\n",
    "    \n",
    "    return neigh.predict(to_predict_features)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xn8B6ekvhiUH"
   },
   "source": [
    "### Let us study the influence of the hyperparameter K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us study the influence of the hyperparameter k (number of neighbors) on KNN algorithm's performance."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aAmoxWKZhiUH"
   },
   "source": [
    "def n_neighbors_influence_multiple_datasize(Ks, dataset_, labels_, N_start, N_end, N_step, loss_=\"manhattan\",\n",
    "                                            folds = 5, show_time=False, visualize=True):\n",
    "    \n",
    "    mean_training_per_k = dict()\n",
    "    std_training_per_k = dict()\n",
    "    mean_validation_per_k = dict()\n",
    "    std_validation_per_k = dict()\n",
    "    \n",
    "    if show_time: time_per_k = dict()\n",
    "    \n",
    "    for k in Ks:\n",
    "        print(k)\n",
    "        if show_time: (mean_trainings, std_trainings, mean_validations, std_validations, times) = data_size_influence(knn, dataset_, labels_, N_start, N_end, N_step, loss_=\"manhattan\", folds = folds, algo_kwargs={\"n_neighbors\":k}, show_time=show_time, visualize=False)\n",
    "        else: (mean_trainings, std_trainings, mean_validations, std_validations) = data_size_influence(knn, dataset_, labels_, N_start, N_end, N_step, loss_=\"manhattan\", folds = folds, algo_kwargs={\"n_neighbors\":k}, show_time=show_time, visualize=False)\n",
    "            \n",
    "        mean_training_per_k[k] = mean_trainings\n",
    "        std_training_per_k[k] = std_trainings\n",
    "        mean_validation_per_k[k]  = mean_validations\n",
    "        std_validation_per_k[k]  = std_validations\n",
    "\n",
    "        if show_time: time_per_k[k]  = times\n",
    "    subplotcode = 120\n",
    "    if show_time :\n",
    "        subplotcode = 130\n",
    "    if visualize:\n",
    "        \n",
    "        Ns = list(range(N_start, N_end, N_step))\n",
    "        \n",
    "        fig = plt.figure(figsize=(15,10))\n",
    "        fig.suptitle(\"Influence of K (in k nearest neighbor) and training/validation dataset size\")\n",
    "        \n",
    "        ax1 = fig.add_subplot(subplotcode+1)\n",
    "        ax1.title.set_text(\"Training precision\")\n",
    "        cmap = plt.get_cmap(\"tab10\")\n",
    "        curveID = 0\n",
    "        for k in Ks:\n",
    "            plotMeanAndStd([i for i in zip(mean_training_per_k[k],std_training_per_k[k])],Ns, legend=\"K = \"+str(k),ax = ax1, color = cmap(curveID))\n",
    "            curveID += 1\n",
    "        ax1.set_ylim(0,1.05)\n",
    "        ax1.set_xlim(N_start,N_end)\n",
    "        ax1.grid()\n",
    "        ax1.legend()\n",
    "        \n",
    "        ax2 = fig.add_subplot(subplotcode+2)\n",
    "        curveID = 0\n",
    "        for k in Ks:\n",
    "            plotMeanAndStd([i for i in zip(mean_validation_per_k[k],std_validation_per_k[k])],Ns, legend=\"K = \"+str(k), ax=ax2,color = cmap(curveID))\n",
    "            curveID += 1\n",
    "        ax2.set_ylim(0,1.05)\n",
    "        ax2.title.set_text(\"Validation precision\")\n",
    "        ax2.set_xlim(N_start,N_end)\n",
    "        ax2.grid()\n",
    "        ax2.legend()\n",
    "        \n",
    "        if show_time:\n",
    "            ax5 = fig.add_subplot(subplotcode+3)\n",
    "            ax5.title.set_text(\"Computation time\")\n",
    "            for k in Ks:\n",
    "                ax5.plot(Ns, time_per_k[k], label=f\"k={k}\")\n",
    "            ax5.grid()\n",
    "            plt.legend()\n",
    "        \n",
    "\n",
    "\n",
    "        fig.tight_layout()\n",
    "              \n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    if show_time: return (mean_training_per_k, std_training_per_k, mean_validation_per_k, std_validation_per_k, time_per_k)\n",
    "    else: return (mean_training_per_k, std_training_per_k, mean_validation_per_k, std_validation_per_k)\n",
    "    "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Dt4zxc5thiUJ"
   },
   "source": [
    "n_neighbors_influence_multiple_datasize(list(range(1, 6)), dataset_adult, labels_adult, 50, 10000, 500, loss_=\"manhattan\",\n",
    "                          folds = 5, show_time=False, visualize=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "53lnubXDhiUK"
   },
   "source": [
    "def n_neighbors_influence_fixed_datasize(Ks, dataset_, labels_, N, loss_=\"manhattan\",\n",
    "                                         folds = 5, show_time=False, visualize=True):\n",
    "    nrows = dataset_.shape[0]\n",
    "    mean_trainings = []\n",
    "    std_trainings = []\n",
    "    mean_validations = []\n",
    "    std_validations = []\n",
    "    \n",
    "    if show_time: times = []\n",
    "    \n",
    "    for k in Ks:\n",
    "        indices = list(np.random.choice(nrows, N))\n",
    "        d = dataset_.iloc[indices]\n",
    "        l = labels_.iloc[indices]\n",
    "        \n",
    "        if show_time: t = time.time()\n",
    "        mean_training, std_training, mean_validation, std_validation = cross_validation(knn, d, l, folds = folds, algo_kwargs={\"n_neighbors\": k})\n",
    "        if show_time: times.append(time.time() - t)\n",
    "        \n",
    "        mean_trainings.append(mean_training)\n",
    "        std_trainings.append(std_training)\n",
    "        mean_validations.append(mean_validation)\n",
    "        std_validations.append(std_validation)\n",
    "    \n",
    "    if visualize:\n",
    "        fig = plt.figure(figsize=(15,10))\n",
    "        #fig.suptitle(\"Influence of training/validation dataset size\")\n",
    "        ax1 = fig.gca()\n",
    "        plotMeanAndStd([i for i in zip(mean_trainings, std_trainings)], Ks, ax = ax1, color = 'b', legend=\"Training\")\n",
    "        plotMeanAndStd([i for i in zip(mean_validations, std_validations)], Ks, ax = ax1, color = 'r', legend=\"Validation\")\n",
    "        ax1.set_ylim(0,1.1)\n",
    "        ax1.grid()\n",
    "        ax1.title.set_text(\"Precision\")\n",
    "        ax1.set_xlabel(\"K\")\n",
    "        ax1.set_ylabel(\"Precision\")\n",
    "        ax1.legend()\n",
    "        ax1.set_xlim(min(Ks), max(Ks))\n",
    "        if show_time:\n",
    "            ax5 = fig.add_subplot(235)\n",
    "            ax5.title.set_text(\"Computation time\")\n",
    "            ax5.plot(Ks, times)\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    if show_time: return (mean_trainings, std_trainings, mean_validations, std_validations, times)\n",
    "    else: \n",
    "        return (mean_trainings, std_trainings, mean_validations, std_validations)\n",
    "    "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5q8G-pJchiUL"
   },
   "source": [
    " n_neighbors_influence_fixed_datasize(list(range(1, 100)), dataset_adult, labels_adult, 2000, loss_=\"manhattan\",\n",
    "                                         folds = 5, show_time=False, visualize=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RflEuMffhiUM"
   },
   "source": [
    "### Knn results for dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mmQqwBWhiUM"
   },
   "source": [
    "##### Selecting best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Q_ZLN_qPhiUN"
   },
   "source": [
    "# TO DO : plot the performance depending on K for the entire dataset, choose simplest best K"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yItfwVREhiUN"
   },
   "source": [
    "##### Results on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mvvhRXUfhiUO"
   },
   "source": [
    "# TO DO : print precision of test dataset, add confusion matrix"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvxZzs7EhiUO"
   },
   "source": [
    "### Knn results for dataset 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TB9oc6y0hiUP"
   },
   "source": [
    "##### Selecting best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HBchGgoshiUP"
   },
   "source": [
    "# TO DO : plot the performance depending on K for the entire dataset, choose simplest best K"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_vQSdO2hiUQ"
   },
   "source": [
    "##### Results on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XjfDL3_NhiUQ"
   },
   "source": [
    "# TO DO : print precision of test dataset, add confusion matrix"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGgE3GtJhiUQ"
   },
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1czo2QT4hiUR"
   },
   "source": [
    "We use scikit-learn's decision tree function to design a decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "uO9tUgiNhiUR"
   },
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8HEiu5H3hiUR"
   },
   "source": [
    "def decision_tree(training_features, training_labels, to_predict_features,\n",
    "                  criterion='gini', splitter='best'):\n",
    "    \"\"\"\n",
    "    :param training_features: training features (x)\n",
    "    :param training_labels: training labels (y)\n",
    "    :param to_predict_features: features that we want to predict\n",
    "    :param criterion: {\"best\", \"random\"} Default is \"gini\" for the Gini impurity and \"entropy\" for the information gain\n",
    "    :param splitter: {\"best\", \"random\"} Default is \"best\" to choose the best split and \"random\" to choose the best random split.\n",
    "    :return:Numpy array containing the labels predicted by Decision Tree for the given 'to_predict_features'\n",
    "    \"\"\"\n",
    "    classifier = DecisionTreeClassifier(criterion=criterion, splitter=splitter)\n",
    "    classifier.fit(training_features, training_labels)\n",
    "    \n",
    "    return classifier.predict(to_predict_features)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LsA0O9nIhiUR"
   },
   "source": [
    "# TO DO : see influence of cost function on precision (same graph as for KNN : dataset size on x axis, one trace for each cost function)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PgZFWL9zhiUS"
   },
   "source": [
    "# TO DO : see influence of max depth on precision (same graph as for KNN : fixed data set size, max depth on x axis, precision on y)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "104uJclihiUS"
   },
   "source": [
    "### Decision tree results for dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UElk887whiUS"
   },
   "source": [
    "##### Selecting best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eBxF9uTRhiUT"
   },
   "source": [
    "#TO DO plot precision depending on max depth, one line for each cost function, selecting simplest best model"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ANuC-VchiUT"
   },
   "source": [
    "##### Results on dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j8Y6ADh_hiUT"
   },
   "source": [
    "# Print precision and confusion matrix on test dataset"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnGbkZlrhiUU"
   },
   "source": [
    "### Decision tree results for dataset 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcFCI5xkhiUU"
   },
   "source": [
    "##### Selecting best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CMWoniQkhiUU"
   },
   "source": [
    "#TO DO plot precision depending on max depth, one line for each cost function, selecting simplest best model"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hpd4LWoghiUU"
   },
   "source": [
    "#### Results on dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4WBxebSAhiUV"
   },
   "source": [
    "# Print precision and confusion matrix on test dataset"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvvzULNjhiUV"
   },
   "source": [
    "### Identify the features considered as most important from decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this section is to be able to identify the data features that decision trees identify as most signficant. This could be useful, in particular to weight features according to their importance when performing KNN classication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_importance(training_features, training_labels, criterion='gini',\n",
    "                        splitter='best', visualize = False, nb_top=5):\n",
    "    \"\"\"\n",
    "    Input: training features and labels, decision tree's parameters, whether we want to visualize feature's\n",
    "    importance\n",
    "    \n",
    "    Output: a dictionary giving each feature a score according to its importance in the decision tree\n",
    "    \"\"\"\n",
    "    \n",
    "    classifier = DecisionTreeClassifier(criterion=criterion, splitter=splitter)\n",
    "    classifier.fit(training_features, training_labels)\n",
    "    features_importances = classifier.feature_importances_\n",
    "    \n",
    "    importance = dict()\n",
    "    cols = dataset.columns\n",
    "    for i,v in enumerate(features_importances):\n",
    "        importance[cols[i]] = v\n",
    "    \n",
    "    if visualize:\n",
    "        # Say which features are most important\n",
    "        ordered_features = sorted(importance.keys(), key = lambda k:(importance[k])) \n",
    "        ordered_features.reverse()\n",
    "        for i in range(nb_top):\n",
    "            feature = ordered_features[i]\n",
    "            print(f\"Feature ranked {i + 1} is {feature} with score {importance[feature]}\")\n",
    "            \n",
    "        # Plot feature importance\n",
    "        plt.bar([x for x in range(len(features_importances))], features_importances)\n",
    "        plt.show()\n",
    "    \n",
    "    return importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence of dataset's size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzYZsoQlhiUV"
   },
   "source": [
    "Now we study the influence of the size of the training / validation dataset on the training / validation errors."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZHaJgF0ohiUV"
   },
   "source": [
    "data_size_influence(knn, dataset, labels, 50, 10000, 1000, loss_=\"manhattan\", folds = 5, algo_kwargs={\"n_neighbors\":3}, show_time=True, visualize=True)\n",
    "pass"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KF22sDhFhiUX"
   },
   "source": [
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WuRHWlRBhiUY"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5yHI7yS5hiUY"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
