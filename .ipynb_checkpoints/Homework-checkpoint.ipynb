{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# For results repeatability\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training / Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/adult.data\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns = [\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[(dataset!=\" ?\").all(axis=1)].reset_index(drop=True)\n",
    "df_strings = dataset.select_dtypes(['object'])\n",
    "dataset[df_strings.columns] = df_strings.apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dataset = pd.DataFrame(dataset[\"age\"])\n",
    "for col in dataset.columns[1:-1]:\n",
    "    if(dataset[col].dtype =='O'):\n",
    "        clean_dataset = clean_dataset.join(pd.get_dummies(dataset[col], prefix=col))\n",
    "    else:\n",
    "        clean_dataset = clean_dataset.join(dataset[col])\n",
    "labels = (dataset[\"salary\"]==\">50K\")*1\n",
    "dataset = clean_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/adult.test\", sep=\",\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['|1x3 Cross validator'], dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16281, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>|1x3 Cross validator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <th>Private</th>\n",
       "      <th>226802</th>\n",
       "      <th>11th</th>\n",
       "      <th>7</th>\n",
       "      <th>Never-married</th>\n",
       "      <th>Machine-op-inspct</th>\n",
       "      <th>Own-child</th>\n",
       "      <th>Black</th>\n",
       "      <th>Male</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>40</th>\n",
       "      <th>United-States</th>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <th>Private</th>\n",
       "      <th>89814</th>\n",
       "      <th>HS-grad</th>\n",
       "      <th>9</th>\n",
       "      <th>Married-civ-spouse</th>\n",
       "      <th>Farming-fishing</th>\n",
       "      <th>Husband</th>\n",
       "      <th>White</th>\n",
       "      <th>Male</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>50</th>\n",
       "      <th>United-States</th>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <th>Local-gov</th>\n",
       "      <th>336951</th>\n",
       "      <th>Assoc-acdm</th>\n",
       "      <th>12</th>\n",
       "      <th>Married-civ-spouse</th>\n",
       "      <th>Protective-serv</th>\n",
       "      <th>Husband</th>\n",
       "      <th>White</th>\n",
       "      <th>Male</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>40</th>\n",
       "      <th>United-States</th>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <th>Private</th>\n",
       "      <th>160323</th>\n",
       "      <th>Some-college</th>\n",
       "      <th>10</th>\n",
       "      <th>Married-civ-spouse</th>\n",
       "      <th>Machine-op-inspct</th>\n",
       "      <th>Husband</th>\n",
       "      <th>Black</th>\n",
       "      <th>Male</th>\n",
       "      <th>7688</th>\n",
       "      <th>0</th>\n",
       "      <th>40</th>\n",
       "      <th>United-States</th>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <th>?</th>\n",
       "      <th>103497</th>\n",
       "      <th>Some-college</th>\n",
       "      <th>10</th>\n",
       "      <th>Never-married</th>\n",
       "      <th>?</th>\n",
       "      <th>Own-child</th>\n",
       "      <th>White</th>\n",
       "      <th>Female</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>30</th>\n",
       "      <th>United-States</th>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <th>Private</th>\n",
       "      <th>215419</th>\n",
       "      <th>Bachelors</th>\n",
       "      <th>13</th>\n",
       "      <th>Divorced</th>\n",
       "      <th>Prof-specialty</th>\n",
       "      <th>Not-in-family</th>\n",
       "      <th>White</th>\n",
       "      <th>Female</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>36</th>\n",
       "      <th>United-States</th>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <th>?</th>\n",
       "      <th>321403</th>\n",
       "      <th>HS-grad</th>\n",
       "      <th>9</th>\n",
       "      <th>Widowed</th>\n",
       "      <th>?</th>\n",
       "      <th>Other-relative</th>\n",
       "      <th>Black</th>\n",
       "      <th>Male</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>40</th>\n",
       "      <th>United-States</th>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <th>Private</th>\n",
       "      <th>374983</th>\n",
       "      <th>Bachelors</th>\n",
       "      <th>13</th>\n",
       "      <th>Married-civ-spouse</th>\n",
       "      <th>Prof-specialty</th>\n",
       "      <th>Husband</th>\n",
       "      <th>White</th>\n",
       "      <th>Male</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>50</th>\n",
       "      <th>United-States</th>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <th>Private</th>\n",
       "      <th>83891</th>\n",
       "      <th>Bachelors</th>\n",
       "      <th>13</th>\n",
       "      <th>Divorced</th>\n",
       "      <th>Adm-clerical</th>\n",
       "      <th>Own-child</th>\n",
       "      <th>Asian-Pac-Islander</th>\n",
       "      <th>Male</th>\n",
       "      <th>5455</th>\n",
       "      <th>0</th>\n",
       "      <th>40</th>\n",
       "      <th>United-States</th>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <th>Self-emp-inc</th>\n",
       "      <th>182148</th>\n",
       "      <th>Bachelors</th>\n",
       "      <th>13</th>\n",
       "      <th>Married-civ-spouse</th>\n",
       "      <th>Exec-managerial</th>\n",
       "      <th>Husband</th>\n",
       "      <th>White</th>\n",
       "      <th>Male</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>60</th>\n",
       "      <th>United-States</th>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16281 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                     |1x3 Cross validator\n",
       "25  Private      226802  11th         7   Never-married       Machine-op-inspct  Own-child       Black               Male   0    0 40  United-States               <=50K.\n",
       "38  Private      89814   HS-grad      9   Married-civ-spouse  Farming-fishing    Husband         White               Male   0    0 50  United-States               <=50K.\n",
       "28  Local-gov    336951  Assoc-acdm   12  Married-civ-spouse  Protective-serv    Husband         White               Male   0    0 40  United-States                >50K.\n",
       "44  Private      160323  Some-college 10  Married-civ-spouse  Machine-op-inspct  Husband         Black               Male   7688 0 40  United-States                >50K.\n",
       "18  ?            103497  Some-college 10  Never-married       ?                  Own-child       White               Female 0    0 30  United-States               <=50K.\n",
       "...                                                                                                                                                                   ...\n",
       "39  Private      215419  Bachelors    13  Divorced            Prof-specialty     Not-in-family   White               Female 0    0 36  United-States               <=50K.\n",
       "64  ?            321403  HS-grad      9   Widowed             ?                  Other-relative  Black               Male   0    0 40  United-States               <=50K.\n",
       "38  Private      374983  Bachelors    13  Married-civ-spouse  Prof-specialty     Husband         White               Male   0    0 50  United-States               <=50K.\n",
       "44  Private      83891   Bachelors    13  Divorced            Adm-clerical       Own-child       Asian-Pac-Islander  Male   5455 0 40  United-States               <=50K.\n",
       "35  Self-emp-inc 182148  Bachelors    13  Married-civ-spouse  Exec-managerial    Husband         White               Male   0    0 60  United-States                >50K.\n",
       "\n",
       "[16281 rows x 1 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.rename(columns={col: \"\" for col in columns})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMeanAndStd(stats, x, color='b'):\n",
    "    \"\"\"\n",
    "    Input : array of tuples (mean std) and their x coordinates\n",
    "    \"\"\"\n",
    "    mean = np.array([s[0] for s in stats])\n",
    "    standard_dev = np.array([s[1] for s in stats])\n",
    "    plt.plot(x, mean, c='b')\n",
    "    plt.fill_between(x, mean-standard_dev, mean+standard_dev, alpha=0.2, color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotMeanAndStd([(1,0.5),(2,0.2),(0,0.7)], [0,1,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(predicted_labels, real_labels, loss=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    Input: numpy array containing respectively the labels an algorithm predicted, and the real labels corresponding\n",
    "    to the data. Type of loss we want to use.\n",
    "    \n",
    "    Output: float, the computed loss.\n",
    "    \"\"\"\n",
    "    if loss == \"euclidean\": return euclidean(predicted_labels, real_labels)\n",
    "    elif loss == \"manhattan\": return sum(abs(predicted_labels - real_labels))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use scikit-learn's knn function to design a knn classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(training_features, training_labels, to_predict_features,\n",
    "        n_neighbors=5, weights = \"uniform\", algorithm=\"auto\", p=2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input: Training data, features for which we want to predict the labels, number of neighbors k for knn algo,\n",
    "    features weights system (uniform or distance), algorithm usewd to find closer k neighbors, p is the value\n",
    "    used in the computation of the minkowski distance that is used here, p=1 gives a manhattan distance, p=2 a\n",
    "    euclidian distance.\n",
    "    \n",
    "    Output: Numpy array containing the labels predicted by KNN for the given 'to_predict_features'\n",
    "    \"\"\"\n",
    "    neigh = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm=algorithm, p=p)\n",
    "    neigh.fit(training_features, training_labels)\n",
    "    \n",
    "    return neigh.predict(to_predict_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size_influence(knn, dataset, labels, 50, 20000, 500, loss_=\"manhattan\", folds = 5, algo_kwargs={\"n_neighbors\":3}, show_time=True, visualize=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us study the influence of the hyperparameter k (number of neighbors) on KNN algorithm's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_neighbors_influence_multiple_datasize(Ks, dataset_, labels_, N_start, N_end, N_step, loss_=\"manhattan\",\n",
    "                                            folds = 5, show_time=False, visualize=True):\n",
    "    \n",
    "    mean_training_per_k = dict()\n",
    "    std_training_per_k = dict()\n",
    "    mean_validation_per_k = dict()\n",
    "    std_validation_per_k = dict()\n",
    "    \n",
    "    if show_time: time_per_k = dict()\n",
    "    \n",
    "    for k in Ks:\n",
    "        print(k)\n",
    "        if show_time: (mean_trainings, std_trainings, mean_validations, std_validations, times) = data_size_influence(knn, dataset_, labels_, N_start, N_end, N_step, loss_=\"manhattan\", folds = folds, algo_kwargs={\"n_neighbors\":k}, show_time=show_time, visualize=False)\n",
    "        else: (mean_trainings, std_trainings, mean_validations, std_validations) = data_size_influence(knn, dataset_, labels_, N_start, N_end, N_step, loss_=\"manhattan\", folds = folds, algo_kwargs={\"n_neighbors\":k}, show_time=show_time, visualize=False)\n",
    "            \n",
    "        mean_training_per_k[k] = mean_trainings\n",
    "        std_training_per_k[k] = std_trainings\n",
    "        mean_validation_per_k[k]  = mean_validations\n",
    "        std_validation_per_k[k]  = std_validations\n",
    "\n",
    "        if show_time: time_per_k[k]  = times\n",
    "    \n",
    "    if visualize:\n",
    "        \n",
    "        Ns = list(range(N_start, N_end, N_step))\n",
    "        \n",
    "        fig = plt.figure(figsize=(10,7))\n",
    "        fig.suptitle(\"Influence of K (in k nearest neighbor) and training/validation dataset size\")\n",
    "        \n",
    "        ax1 = fig.add_subplot(231)\n",
    "        ax1.title.set_text(\"Mean training precision\")\n",
    "        for k in Ks:\n",
    "            ax1.plot(Ns, mean_training_per_k[k], label=f\"k={k}\")\n",
    "        plt.legend()\n",
    "\n",
    "        ax2 = fig.add_subplot(232)\n",
    "        ax2.title.set_text(\"Training precision's standard deviation\")\n",
    "        for k in Ks:\n",
    "            ax2.plot(Ns, std_training_per_k[k], label=f\"k={k}\")\n",
    "        plt.legend()\n",
    "\n",
    "        ax3 = fig.add_subplot(233)\n",
    "        ax3.title.set_text(\"Mean validation precision\")\n",
    "        for k in Ks:\n",
    "            ax3.plot(Ns, mean_validation_per_k[k], label=f\"k={k}\")\n",
    "        plt.legend()\n",
    "\n",
    "        ax4 = fig.add_subplot(234)\n",
    "        ax4.title.set_text(\"Validation precision's standard deviation\")\n",
    "        for k in Ks:\n",
    "            ax4.plot(Ns, std_validation_per_k[k], label=f\"k={k}\")\n",
    "        plt.legend()\n",
    "\n",
    "        if show_time:\n",
    "            ax5 = fig.add_subplot(235)\n",
    "            ax5.title.set_text(\"Computation time\")\n",
    "            for k in Ks:\n",
    "                ax5.plot(Ns, time_per_k[k], label=f\"k={k}\")\n",
    "            plt.legend()\n",
    "        \n",
    "        \n",
    "        plt.subplots_adjust(left=0.1,\n",
    "                        bottom=0.1, \n",
    "                        right=3, \n",
    "                        top=3, \n",
    "                        wspace=1, \n",
    "                        hspace=1)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    if show_time: return (mean_training_per_k, std_training_per_k, mean_validation_per_k, std_validation_per_k, time_per_k)\n",
    "    else: return (mean_training_per_k, std_training_per_k, mean_validation_per_k, std_validation_per_k)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors_influence(list(range(1, 6)), dataset, labels, 50, 10000, 500, loss_=\"manhattan\",\n",
    "                          folds = 5, show_time=False, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_neighbors_influence_fixed_datasize(Ks, dataset_, labels_, N, loss_=\"manhattan\",\n",
    "                                         folds = 5, show_time=False, visualize=True):\n",
    "    nrows = dataset_.shape[0]\n",
    "    mean_trainings = []\n",
    "    std_trainings = []\n",
    "    mean_validations = []\n",
    "    std_validations = []\n",
    "    \n",
    "    if show_time: times = []\n",
    "    \n",
    "    for k in Ks:\n",
    "        indices = list(np.random.choice(nrows, N))\n",
    "        d = dataset.iloc[indices]\n",
    "        l = labels.iloc[indices]\n",
    "        \n",
    "        if show_time: t = time.time()\n",
    "        mean_training, std_training, mean_validation, std_validation = cross_validation(knn, d, l, folds = folds, algo_kwargs={\"n_neighbors\": k})\n",
    "        if show_time: times.append(time.time() - t)\n",
    "        \n",
    "        mean_trainings.append(mean_training)\n",
    "        std_trainings.append(std_training)\n",
    "        mean_validations.append(mean_validation)\n",
    "        std_validations.append(std_validation)\n",
    "    \n",
    "    if visualize:\n",
    "        fig = plt.figure(figsize=(10,7))\n",
    "        fig.suptitle(\"Influence of training/validation dataset size\")\n",
    "        ax1 = fig.add_subplot(231)\n",
    "        ax1.title.set_text(\"Mean training precision\")\n",
    "        ax1.plot(Ks, mean_trainings)\n",
    "\n",
    "        ax2 = fig.add_subplot(232)\n",
    "        ax2.title.set_text(\"Training precision's standard deviation\")\n",
    "        ax2.plot(Ks, std_trainings)\n",
    "\n",
    "        ax3 = fig.add_subplot(233)\n",
    "        ax3.title.set_text(\"Mean validation precision\")\n",
    "        ax3.plot(Ks, mean_validations)\n",
    "\n",
    "        ax4 = fig.add_subplot(234)\n",
    "        ax4.title.set_text(\"Validation precision's standard deviation\")\n",
    "        ax4.plot(Ks, std_validations)\n",
    "\n",
    "        if show_time:\n",
    "            ax5 = fig.add_subplot(235)\n",
    "            ax5.title.set_text(\"Computation time\")\n",
    "            ax5.plot(Ks, times)\n",
    "        \n",
    "        plt.subplots_adjust(left=0.1,\n",
    "                        bottom=0.1, \n",
    "                        right=3, \n",
    "                        top=3, \n",
    "                        wspace=1, \n",
    "                        hspace=1)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    if show_time: return (mean_trainings, std_trainings, mean_validations, std_validations, times)\n",
    "    else: \n",
    "        return (mean_trainings, std_trainings, mean_validations, std_validations)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " n_neighbors_influence_fixed_datasize(list(range(1, 100)), dataset, labels, 2000, loss_=\"manhattan\",\n",
    "                                         folds = 5, show_time=False, visualize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knn results for dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting best hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results on test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knn results for dataset 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting best hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results on test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use scikit-learn's decision tree function to design a decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(training_features, training_labels, to_predict_features,\n",
    "                  criterion='gini', splitter='best'):\n",
    "    \"\"\"\n",
    "    :param training_features: training features (x)\n",
    "    :param training_labels: training labels (y)\n",
    "    :param to_predict_features: features that we want to predict\n",
    "    :param criterion: {\"best\", \"random\"} Default is \"gini\" for the Gini impurity and \"entropy\" for the information gain\n",
    "    :param splitter: {\"best\", \"random\"} Default is \"best\" to choose the best split and \"random\" to choose the best random split.\n",
    "    :return:Numpy array containing the labels predicted by Decision Tree for the given 'to_predict_features'\n",
    "    \"\"\"\n",
    "    classifier = DecisionTreeClassifier(criterion=criterion, splitter=splitter)\n",
    "    classifier.fit(training_features, training_labels)\n",
    "    \n",
    "    return classifier.predict(to_predict_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = dataset[0:1000]\n",
    "training_labels = labels[0:1000]\n",
    "to_predict_features = dataset[1000:1200]\n",
    "predicted_labels = decision_tree(training_features, training_labels, to_predict_features)\n",
    "real_labels = labels[1000:1200]\n",
    "print(error(predicted_labels, real_labels, loss=\"manhattan\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = dataset[0:1000]\n",
    "training_labels = labels[0:1000]\n",
    "to_predict_features = dataset[1000:1200]\n",
    "predicted_labels = decision_tree(training_features, training_labels, to_predict_features)\n",
    "real_labels = labels[1000:1200]\n",
    "print(error(predicted_labels, real_labels, loss=\"manhattan\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(algo, dataset_, labels_, loss_=\"manhattan\", folds = 5, algo_kwargs={}):\n",
    "    \"\"\"\n",
    "    Input : Predictor function that works by supplying training set and labels and test set and return predicted labels\n",
    "            dataset  and corresponding labels\n",
    "            folds\n",
    "            algo_kwargs : a dict with additional params for the algo : ex. {'n_neighbors':5}\n",
    "    Output : Precision mean and variance\n",
    "    \"\"\"\n",
    "    dataset_size = dataset_.shape[0]\n",
    "    group_ids = np.tile(np.arange(folds),int(dataset_size/folds)+1)[:dataset_size]\n",
    "    np.random.shuffle(group_ids)\n",
    "    training_precisions = []\n",
    "    validation_precisions = []\n",
    "    for N in range(folds):\n",
    "        training_set = dataset_[group_ids != N]\n",
    "        training_labels = labels_[group_ids != N]\n",
    "        test_set = dataset_[group_ids == N]\n",
    "        test_labels = labels_[group_ids == N]\n",
    "        # Training error\n",
    "        training_predicted_labels = algo(training_set, training_labels, training_set, **algo_kwargs)\n",
    "        training_precisions += [(len(training_labels) - error(training_predicted_labels, training_labels, loss = loss_))/len(training_labels)]\n",
    "    \n",
    "        \n",
    "        # Validation error\n",
    "        validation_predicted_labels = algo(training_set, training_labels, test_set, **algo_kwargs)\n",
    "        validation_precisions += [(len(test_labels) - error(validation_predicted_labels, test_labels, loss = loss_))/len(test_labels)]\n",
    "    \n",
    "    \n",
    "    return (np.mean(training_precisions), np.std(training_precisions), np.mean(validation_precisions), np.std(validation_precisions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation(knn, dataset[:1000], labels[:1000], folds = 10, algo_kwargs={'n_neighbors':3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence of dataset's size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we study the influence of the size of the training / validation dataset on the training / validation errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_size_influence(algo, dataset_, labels_, N_start, N_end, N_step, loss_=\"manhattan\", folds = 5, algo_kwargs={}, show_time=False, visualize=True):\n",
    "    \n",
    "    nrows = dataset_.shape[0]\n",
    "    Ns = []\n",
    "    mean_trainings = []\n",
    "    std_trainings = []\n",
    "    mean_validations = []\n",
    "    std_validations = []\n",
    "    \n",
    "    if show_time: times = []\n",
    "    \n",
    "    for N in range(N_start, N_end, N_step):\n",
    "        Ns.append(N)\n",
    "        indices = list(np.random.choice(nrows, N))\n",
    "        d = dataset.iloc[indices]\n",
    "        l = labels.iloc[indices]\n",
    "        \n",
    "        if show_time: t = time.time()\n",
    "        mean_training, std_training, mean_validation, std_validation = cross_validation(knn, d, l, folds = folds, algo_kwargs=algo_kwargs)\n",
    "        if show_time: times.append(time.time() - t)\n",
    "        \n",
    "        mean_trainings.append(mean_training)\n",
    "        std_trainings.append(std_training)\n",
    "        mean_validations.append(mean_validation)\n",
    "        std_validations.append(std_validation)\n",
    "    \n",
    "    if visualize:\n",
    "        fig = plt.figure(figsize=(10,7))\n",
    "        fig.suptitle(\"Influence of training/validation dataset size\")\n",
    "        ax1 = fig.add_subplot(231)\n",
    "        ax1.title.set_text(\"Mean training precision\")\n",
    "        ax1.plot(Ns, mean_trainings)\n",
    "\n",
    "        ax2 = fig.add_subplot(232)\n",
    "        ax2.title.set_text(\"Training precision's standard deviation\")\n",
    "        ax2.plot(Ns, std_trainings)\n",
    "\n",
    "        ax3 = fig.add_subplot(233)\n",
    "        ax3.title.set_text(\"Mean validation precision\")\n",
    "        ax3.plot(Ns, mean_validations)\n",
    "\n",
    "        ax4 = fig.add_subplot(234)\n",
    "        ax4.title.set_text(\"Validation precision's standard deviation\")\n",
    "        ax4.plot(Ns, std_validations)\n",
    "\n",
    "        if show_time:\n",
    "            ax5 = fig.add_subplot(235)\n",
    "            ax5.title.set_text(\"Computation time\")\n",
    "            ax5.plot(Ns, times)\n",
    "        plt.subplots_adjust(left=0.1,\n",
    "                        bottom=0.1, \n",
    "                        right=3, \n",
    "                        top=3, \n",
    "                        wspace=1, \n",
    "                        hspace=1)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    if show_time: return (mean_trainings, std_trainings, mean_validations, std_validations, times)\n",
    "    else: return (mean_trainings, std_trainings, mean_validations, std_validations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size_influence(knn, dataset, labels, 50, 10000, 500, loss_=\"manhattan\", folds = 5, algo_kwargs={\"n_neighbors\":3}, show_time=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
