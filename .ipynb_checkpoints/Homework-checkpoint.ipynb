{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# For results repeatability\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/adult.data\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns = [\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[(dataset!=\" ?\").all(axis=1)].reset_index(drop=True)\n",
    "df_strings = dataset.select_dtypes(['object'])\n",
    "dataset[df_strings.columns] = df_strings.apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dataset = pd.DataFrame(dataset[\"age\"])\n",
    "for col in dataset.columns[1:-1]:\n",
    "    if(dataset[col].dtype =='O'):\n",
    "        clean_dataset = clean_dataset.join(pd.get_dummies(dataset[col], prefix=col))\n",
    "    else:\n",
    "        clean_dataset = clean_dataset.join(dataset[col])\n",
    "labels = (dataset[\"salary\"]==\">50K\")*1\n",
    "dataset = clean_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMeanAndStd(stats, x, color='b'):\n",
    "    \"\"\"\n",
    "    Input : array of tuples (mean std) and their x coordinates\n",
    "    \"\"\"\n",
    "    mean = np.array([s[0] for s in stats])\n",
    "    standard_dev = np.array([s[1] for s in stats])\n",
    "    plt.plot(x, mean, c='b')\n",
    "    plt.fill_between(x, mean-standard_dev, mean+standard_dev, alpha=0.2, color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotMeanAndStd([(1,0.5),(2,0.2),(0,0.7)], [0,1,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(predicted_labels, real_labels, loss=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    Input: numpy array containing respectively the labels an algorithm predicted, and the real labels corresponding\n",
    "    to the data. Type of loss we want to use.\n",
    "    \n",
    "    Output: float, the computed loss.\n",
    "    \"\"\"\n",
    "    if loss == \"euclidean\": return euclidean(predicted_labels, real_labels)\n",
    "    elif loss == \"manhattan\": return sum(abs(predicted_labels - real_labels))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use scikit-learn's knn function to design a knn classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(training_features, training_labels, to_predict_features,\n",
    "        n_neighbors=5, weights = \"uniform\", algorithm=\"auto\", p=2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input: Training data, features for which we want to predict the labels, number of neighbors k for knn algo,\n",
    "    features weights system (uniform or distance), algorithm usewd to find closer k neighbors, p is the value\n",
    "    used in the computation of the minkowski distance that is used here, p=1 gives a manhattan distance, p=2 a\n",
    "    euclidian distance.\n",
    "    \n",
    "    Output: Numpy array containing the labels predicted by KNN for the given 'to_predict_features'\n",
    "    \"\"\"\n",
    "    neigh = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm=algorithm, p=p)\n",
    "    neigh.fit(training_features, training_labels)\n",
    "    \n",
    "    return neigh.predict(to_predict_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size_influence(knn, dataset, labels, 50, 20000, 500, loss_=\"manhattan\", folds = 5, algo_kwargs={\"n_neighbors\":3}, show_time=True, visualize=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us study the influence of the hyperparameter k (number of neighbors) on KNN algorithm's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_neighbors_influence_multiple_datasize(Ks, dataset_, labels_, N_start, N_end, N_step, loss_=\"manhattan\",\n",
    "                                            folds = 5, show_time=False, visualize=True):\n",
    "    \n",
    "    mean_training_per_k = dict()\n",
    "    std_training_per_k = dict()\n",
    "    mean_validation_per_k = dict()\n",
    "    std_validation_per_k = dict()\n",
    "    \n",
    "    if show_time: time_per_k = dict()\n",
    "    \n",
    "    for k in Ks:\n",
    "        print(k)\n",
    "        if show_time: (mean_trainings, std_trainings, mean_validations, std_validations, times) = data_size_influence(knn, dataset_, labels_, N_start, N_end, N_step, loss_=\"manhattan\", folds = folds, algo_kwargs={\"n_neighbors\":k}, show_time=show_time, visualize=False)\n",
    "        else: (mean_trainings, std_trainings, mean_validations, std_validations) = data_size_influence(knn, dataset_, labels_, N_start, N_end, N_step, loss_=\"manhattan\", folds = folds, algo_kwargs={\"n_neighbors\":k}, show_time=show_time, visualize=False)\n",
    "            \n",
    "        mean_training_per_k[k] = mean_trainings\n",
    "        std_training_per_k[k] = std_trainings\n",
    "        mean_validation_per_k[k]  = mean_validations\n",
    "        std_validation_per_k[k]  = std_validations\n",
    "\n",
    "        if show_time: time_per_k[k]  = times\n",
    "    \n",
    "    if visualize:\n",
    "        \n",
    "        Ns = list(range(N_start, N_end, N_step))\n",
    "        \n",
    "        fig = plt.figure(figsize=(10,7))\n",
    "        fig.suptitle(\"Influence of K (in k nearest neighbor) and training/validation dataset size\")\n",
    "        \n",
    "        ax1 = fig.add_subplot(231)\n",
    "        ax1.title.set_text(\"Mean training precision\")\n",
    "        for k in Ks:\n",
    "            ax1.plot(Ns, mean_training_per_k[k], label=f\"k={k}\")\n",
    "        plt.legend()\n",
    "\n",
    "        ax2 = fig.add_subplot(232)\n",
    "        ax2.title.set_text(\"Training precision's standard deviation\")\n",
    "        for k in Ks:\n",
    "            ax2.plot(Ns, std_training_per_k[k], label=f\"k={k}\")\n",
    "        plt.legend()\n",
    "\n",
    "        ax3 = fig.add_subplot(233)\n",
    "        ax3.title.set_text(\"Mean validation precision\")\n",
    "        for k in Ks:\n",
    "            ax3.plot(Ns, mean_validation_per_k[k], label=f\"k={k}\")\n",
    "        plt.legend()\n",
    "\n",
    "        ax4 = fig.add_subplot(234)\n",
    "        ax4.title.set_text(\"Validation precision's standard deviation\")\n",
    "        for k in Ks:\n",
    "            ax4.plot(Ns, std_validation_per_k[k], label=f\"k={k}\")\n",
    "        plt.legend()\n",
    "\n",
    "        if show_time:\n",
    "            ax5 = fig.add_subplot(235)\n",
    "            ax5.title.set_text(\"Computation time\")\n",
    "            for k in Ks:\n",
    "                ax5.plot(Ns, time_per_k[k], label=f\"k={k}\")\n",
    "            plt.legend()\n",
    "        \n",
    "        \n",
    "        plt.subplots_adjust(left=0.1,\n",
    "                        bottom=0.1, \n",
    "                        right=3, \n",
    "                        top=3, \n",
    "                        wspace=1, \n",
    "                        hspace=1)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    if show_time: return (mean_training_per_k, std_training_per_k, mean_validation_per_k, std_validation_per_k, time_per_k)\n",
    "    else: return (mean_training_per_k, std_training_per_k, mean_validation_per_k, std_validation_per_k)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors_influence(list(range(1, 6)), dataset, labels, 50, 10000, 500, loss_=\"manhattan\",\n",
    "                          folds = 5, show_time=False, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_neighbors_influence_fixed_datasize(Ks, dataset_, labels_, N, loss_=\"manhattan\",\n",
    "                                         folds = 5, show_time=False, visualize=True):\n",
    "    nrows = dataset_.shape[0]\n",
    "    mean_trainings = []\n",
    "    std_trainings = []\n",
    "    mean_validations = []\n",
    "    std_validations = []\n",
    "    \n",
    "    if show_time: times = []\n",
    "    \n",
    "    for k in Ks:\n",
    "        indices = list(np.random.choice(nrows, N))\n",
    "        d = dataset.iloc[indices]\n",
    "        l = labels.iloc[indices]\n",
    "        \n",
    "        if show_time: t = time.time()\n",
    "        mean_training, std_training, mean_validation, std_validation = cross_validation(knn, d, l, folds = folds, algo_kwargs={\"n_neighbors\": k})\n",
    "        if show_time: times.append(time.time() - t)\n",
    "        \n",
    "        mean_trainings.append(mean_training)\n",
    "        std_trainings.append(std_training)\n",
    "        mean_validations.append(mean_validation)\n",
    "        std_validations.append(std_validation)\n",
    "    \n",
    "    if visualize:\n",
    "        fig = plt.figure(figsize=(10,7))\n",
    "        fig.suptitle(\"Influence of training/validation dataset size\")\n",
    "        ax1 = fig.add_subplot(231)\n",
    "        ax1.title.set_text(\"Mean training precision\")\n",
    "        ax1.plot(Ks, mean_trainings)\n",
    "\n",
    "        ax2 = fig.add_subplot(232)\n",
    "        ax2.title.set_text(\"Training precision's standard deviation\")\n",
    "        ax2.plot(Ks, std_trainings)\n",
    "\n",
    "        ax3 = fig.add_subplot(233)\n",
    "        ax3.title.set_text(\"Mean validation precision\")\n",
    "        ax3.plot(Ks, mean_validations)\n",
    "\n",
    "        ax4 = fig.add_subplot(234)\n",
    "        ax4.title.set_text(\"Validation precision's standard deviation\")\n",
    "        ax4.plot(Ks, std_validations)\n",
    "\n",
    "        if show_time:\n",
    "            ax5 = fig.add_subplot(235)\n",
    "            ax5.title.set_text(\"Computation time\")\n",
    "            ax5.plot(Ks, times)\n",
    "        \n",
    "        plt.subplots_adjust(left=0.1,\n",
    "                        bottom=0.1, \n",
    "                        right=3, \n",
    "                        top=3, \n",
    "                        wspace=1, \n",
    "                        hspace=1)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    if show_time: return (mean_trainings, std_trainings, mean_validations, std_validations, times)\n",
    "    else: \n",
    "        return (mean_trainings, std_trainings, mean_validations, std_validations)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " n_neighbors_influence_fixed_datasize(list(range(1, 100)), dataset, labels, 2000, loss_=\"manhattan\",\n",
    "                                         folds = 5, show_time=False, visualize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knn results for dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting best hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results on test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knn results for dataset 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting best hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results on test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use scikit-learn's decision tree function to design a decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(training_features, training_labels, to_predict_features,\n",
    "                  criterion='gini', splitter='best'):\n",
    "    \"\"\"\n",
    "    :param training_features: training features (x)\n",
    "    :param training_labels: training labels (y)\n",
    "    :param to_predict_features: features that we want to predict\n",
    "    :param criterion: {\"best\", \"random\"} Default is \"gini\" for the Gini impurity and \"entropy\" for the information gain\n",
    "    :param splitter: {\"best\", \"random\"} Default is \"best\" to choose the best split and \"random\" to choose the best random split.\n",
    "    :return:Numpy array containing the labels predicted by Decision Tree for the given 'to_predict_features'\n",
    "    \"\"\"\n",
    "    classifier = DecisionTreeClassifier(criterion=criterion, splitter=splitter)\n",
    "    classifier.fit(training_features, training_labels)\n",
    "    \n",
    "    return classifier.predict(to_predict_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = dataset[0:1000]\n",
    "training_labels = labels[0:1000]\n",
    "to_predict_features = dataset[1000:1200]\n",
    "predicted_labels = decision_tree(training_features, training_labels, to_predict_features)\n",
    "real_labels = labels[1000:1200]\n",
    "print(error(predicted_labels, real_labels, loss=\"manhattan\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = dataset[0:1000]\n",
    "training_labels = labels[0:1000]\n",
    "to_predict_features = dataset[1000:1200]\n",
    "predicted_labels = decision_tree(training_features, training_labels, to_predict_features)\n",
    "real_labels = labels[1000:1200]\n",
    "print(error(predicted_labels, real_labels, loss=\"manhattan\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(algo, dataset_, labels_, loss_=\"manhattan\", folds = 5, algo_kwargs={}):\n",
    "    \"\"\"\n",
    "    Input : Predictor function that works by supplying training set and labels and test set and return predicted labels\n",
    "            dataset  and corresponding labels\n",
    "            folds\n",
    "            algo_kwargs : a dict with additional params for the algo : ex. {'n_neighbors':5}\n",
    "    Output : Precision mean and variance\n",
    "    \"\"\"\n",
    "    dataset_size = dataset_.shape[0]\n",
    "    group_ids = np.tile(np.arange(folds),int(dataset_size/folds)+1)[:dataset_size]\n",
    "    np.random.shuffle(group_ids)\n",
    "    training_precisions = []\n",
    "    validation_precisions = []\n",
    "    for N in range(folds):\n",
    "        training_set = dataset_[group_ids != N]\n",
    "        training_labels = labels_[group_ids != N]\n",
    "        test_set = dataset_[group_ids == N]\n",
    "        test_labels = labels_[group_ids == N]\n",
    "        # Training error\n",
    "        training_predicted_labels = algo(training_set, training_labels, training_set, **algo_kwargs)\n",
    "        training_precisions += [(len(training_labels) - error(training_predicted_labels, training_labels, loss = loss_))/len(training_labels)]\n",
    "    \n",
    "        \n",
    "        # Validation error\n",
    "        validation_predicted_labels = algo(training_set, training_labels, test_set, **algo_kwargs)\n",
    "        validation_precisions += [(len(test_labels) - error(validation_predicted_labels, test_labels, loss = loss_))/len(test_labels)]\n",
    "    \n",
    "    \n",
    "    return (np.mean(training_precisions), np.std(training_precisions), np.mean(validation_precisions), np.std(validation_precisions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation(knn, dataset[:1000], labels[:1000], folds = 10, algo_kwargs={'n_neighbors':3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence of dataset's size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we study the influence of the size of the training / validation dataset on the training / validation errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_size_influence(algo, dataset_, labels_, N_start, N_end, N_step, loss_=\"manhattan\", folds = 5, algo_kwargs={}, show_time=False, visualize=True):\n",
    "    \n",
    "    nrows = dataset_.shape[0]\n",
    "    Ns = []\n",
    "    mean_trainings = []\n",
    "    std_trainings = []\n",
    "    mean_validations = []\n",
    "    std_validations = []\n",
    "    \n",
    "    if show_time: times = []\n",
    "    \n",
    "    for N in range(N_start, N_end, N_step):\n",
    "        Ns.append(N)\n",
    "        indices = list(np.random.choice(nrows, N))\n",
    "        d = dataset.iloc[indices]\n",
    "        l = labels.iloc[indices]\n",
    "        \n",
    "        if show_time: t = time.time()\n",
    "        mean_training, std_training, mean_validation, std_validation = cross_validation(knn, d, l, folds = folds, algo_kwargs=algo_kwargs)\n",
    "        if show_time: times.append(time.time() - t)\n",
    "        \n",
    "        mean_trainings.append(mean_training)\n",
    "        std_trainings.append(std_training)\n",
    "        mean_validations.append(mean_validation)\n",
    "        std_validations.append(std_validation)\n",
    "    \n",
    "    if visualize:\n",
    "        fig = plt.figure(figsize=(10,7))\n",
    "        fig.suptitle(\"Influence of training/validation dataset size\")\n",
    "        ax1 = fig.add_subplot(231)\n",
    "        ax1.title.set_text(\"Mean training precision\")\n",
    "        ax1.plot(Ns, mean_trainings)\n",
    "\n",
    "        ax2 = fig.add_subplot(232)\n",
    "        ax2.title.set_text(\"Training precision's standard deviation\")\n",
    "        ax2.plot(Ns, std_trainings)\n",
    "\n",
    "        ax3 = fig.add_subplot(233)\n",
    "        ax3.title.set_text(\"Mean validation precision\")\n",
    "        ax3.plot(Ns, mean_validations)\n",
    "\n",
    "        ax4 = fig.add_subplot(234)\n",
    "        ax4.title.set_text(\"Validation precision's standard deviation\")\n",
    "        ax4.plot(Ns, std_validations)\n",
    "\n",
    "        if show_time:\n",
    "            ax5 = fig.add_subplot(235)\n",
    "            ax5.title.set_text(\"Computation time\")\n",
    "            ax5.plot(Ns, times)\n",
    "        plt.subplots_adjust(left=0.1,\n",
    "                        bottom=0.1, \n",
    "                        right=3, \n",
    "                        top=3, \n",
    "                        wspace=1, \n",
    "                        hspace=1)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    if show_time: return (mean_trainings, std_trainings, mean_validations, std_validations, times)\n",
    "    else: return (mean_trainings, std_trainings, mean_validations, std_validations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size_influence(knn, dataset, labels, 50, 10000, 500, loss_=\"manhattan\", folds = 5, algo_kwargs={\"n_neighbors\":3}, show_time=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
